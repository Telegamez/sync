/**
 * Video Summary Type Definitions
 *
 * Types for dual-mode voice-activated video intelligence:
 * - Default mode: YouTube API metadata + LLM enhancement (~1-2s)
 * - Deep mode: Transcript-based analysis (~3-10s)
 *
 * Part of the Long-Horizon Engineering Protocol - FEAT-901
 */

import type { RoomId } from "./room";
import type { YouTubeVideoId } from "./video";

// ============================================================================
// Summary Mode Types
// ============================================================================

/**
 * Video summary modes
 * - default: Quick summary using YouTube metadata + LLM (~1-2s)
 * - deep: Comprehensive analysis using transcript + LLM (~3-10s)
 */
export type SummaryMode = "default" | "deep";

/**
 * Voice triggers that map to each mode
 */
export const SUMMARY_MODE_TRIGGERS: Record<SummaryMode, string[]> = {
  default: [
    "what are we watching",
    "what is this video",
    "who made this",
    "quick summary",
    "summarize this",
  ],
  deep: [
    "analyze this video",
    "deep dive",
    "what topics are covered",
    "give me a detailed breakdown",
    "what are the main points",
    "break down this video",
  ],
};

// ============================================================================
// YouTube Metadata Types (from YouTube Data API v3)
// ============================================================================

/**
 * YouTube video metadata from Data API v3
 */
export interface YouTubeVideoMetadata {
  /** YouTube video ID */
  videoId: YouTubeVideoId;
  /** Video title */
  title: string;
  /** Video description (may be truncated) */
  description: string;
  /** Channel name */
  channelTitle: string;
  /** Channel ID */
  channelId: string;
  /** When the video was published */
  publishedAt: string;
  /** Video thumbnail URLs */
  thumbnails: {
    default?: YouTubeThumbnail;
    medium?: YouTubeThumbnail;
    high?: YouTubeThumbnail;
    maxres?: YouTubeThumbnail;
  };
  /** Video tags/keywords */
  tags: string[];
  /** Category ID */
  categoryId: string;
  /** Video duration in ISO 8601 format (e.g., "PT5M30S") */
  duration: string;
  /** Duration in seconds (parsed) */
  durationSeconds: number;
  /** View count */
  viewCount: number;
  /** Like count */
  likeCount: number;
  /** Whether captions are available */
  hasCaption: boolean;
  /** Content rating info */
  contentRating?: string;
}

/**
 * YouTube thumbnail info
 */
export interface YouTubeThumbnail {
  url: string;
  width: number;
  height: number;
}

// ============================================================================
// Transcript Types
// ============================================================================

/**
 * A single segment of video transcript with timestamp
 */
export interface TranscriptSegment {
  /** Text content of this segment */
  text: string;
  /** Start time in seconds */
  start: number;
  /** Duration in seconds */
  duration: number;
  /** End time in seconds (start + duration) */
  end: number;
}

/**
 * Full video transcript
 */
export interface VideoTranscript {
  /** YouTube video ID */
  videoId: YouTubeVideoId;
  /** Language code (e.g., "en", "es") */
  language: string;
  /** Whether this is auto-generated captions */
  isAutoGenerated: boolean;
  /** Transcript segments */
  segments: TranscriptSegment[];
  /** Full transcript as plain text */
  fullText: string;
  /** Total duration covered by transcript */
  totalDuration: number;
}

// ============================================================================
// Summary Request/Response Types
// ============================================================================

/**
 * Request for video summary (from OpenAI function call)
 */
export interface VideoSummaryRequest {
  /** Summary mode: default (quick) or deep (transcript-based) */
  mode: SummaryMode;
  /** Optional: Override video ID (defaults to currently playing) */
  videoId?: YouTubeVideoId;
}

/**
 * Video summary response structure
 */
export interface VideoSummaryResponse {
  /** Which mode was used */
  mode: SummaryMode;
  /** Whether fallback was used (deep -> default if no transcript) */
  usedFallback: boolean;
  /** Video metadata */
  metadata: YouTubeVideoMetadata;
  /** Generated summary text (for AI to speak) */
  summary: string;
  /** Key points extracted (for deep mode) */
  keyPoints?: string[];
  /** Topics covered (for deep mode) */
  topics?: string[];
  /** Notable speakers/people mentioned (for deep mode) */
  speakers?: string[];
  /** Timestamp of summary generation */
  generatedAt: number;
  /** Processing time in milliseconds */
  processingTimeMs: number;
}

/**
 * Error response for video summary
 */
export interface VideoSummaryError {
  /** Error code */
  code:
    | "NO_VIDEO_PLAYING"
    | "VIDEO_NOT_FOUND"
    | "API_ERROR"
    | "TRANSCRIPT_UNAVAILABLE"
    | "RATE_LIMITED"
    | "UNKNOWN";
  /** Human-readable error message */
  message: string;
  /** Mode that was requested */
  requestedMode: SummaryMode;
}

// ============================================================================
// Function Call Types (for OpenAI Realtime API)
// ============================================================================

/**
 * Arguments for getVideoSummary function call
 */
export interface GetVideoSummaryArgs {
  /** Summary mode */
  mode: SummaryMode;
}

/**
 * Function output for getVideoSummary
 */
export interface GetVideoSummaryOutput {
  /** Whether the request was successful */
  success: boolean;
  /** Summary response (if successful) */
  response?: VideoSummaryResponse;
  /** Error details (if failed) */
  error?: VideoSummaryError;
}

// ============================================================================
// Socket.io Event Payload Types
// ============================================================================

/**
 * Payload for video:summary event
 */
export interface VideoSummaryPayload {
  /** Room ID */
  roomId: RoomId;
  /** Summary response */
  summary: VideoSummaryResponse;
}

/**
 * Payload for video:summary-error event
 */
export interface VideoSummaryErrorPayload {
  /** Room ID */
  roomId: RoomId;
  /** Error details */
  error: VideoSummaryError;
}

// ============================================================================
// Client-Side State Types
// ============================================================================

/**
 * Video summary loading state
 */
export type VideoSummaryLoadingState = "idle" | "loading" | "success" | "error";

/**
 * Client-side video summary state for useVideoSummary hook
 */
export interface VideoSummaryState {
  /** Current loading state */
  loadingState: VideoSummaryLoadingState;
  /** Last successful summary */
  lastSummary: VideoSummaryResponse | null;
  /** Current error (if any) */
  error: VideoSummaryError | null;
  /** Timestamp of last update */
  lastUpdatedAt: number | null;
}

/**
 * Initial client-side video summary state
 */
export const INITIAL_VIDEO_SUMMARY_STATE: VideoSummaryState = {
  loadingState: "idle",
  lastSummary: null,
  error: null,
  lastUpdatedAt: null,
};

// ============================================================================
// Cache Types
// ============================================================================

/**
 * Cached metadata entry
 */
export interface CachedMetadata {
  /** The cached metadata */
  data: YouTubeVideoMetadata;
  /** When the cache entry was created */
  cachedAt: number;
  /** TTL in milliseconds (default: 15 minutes) */
  ttl: number;
}

/**
 * Cached transcript entry
 */
export interface CachedTranscript {
  /** The cached transcript */
  data: VideoTranscript;
  /** When the cache entry was created */
  cachedAt: number;
  /** TTL in milliseconds (default: 1 hour) */
  ttl: number;
}

/**
 * Default cache TTLs
 */
export const CACHE_TTL = {
  /** Metadata cache: 15 minutes */
  METADATA: 15 * 60 * 1000,
  /** Transcript cache: 1 hour */
  TRANSCRIPT: 60 * 60 * 1000,
} as const;

// ============================================================================
// Utility Functions
// ============================================================================

/**
 * Parse ISO 8601 duration to seconds
 * @param duration - ISO 8601 duration string (e.g., "PT5M30S")
 * @returns Duration in seconds
 */
export function parseIsoDuration(duration: string): number {
  const match = duration.match(/PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?/);
  if (!match) return 0;

  const hours = parseInt(match[1] || "0", 10);
  const minutes = parseInt(match[2] || "0", 10);
  const seconds = parseInt(match[3] || "0", 10);

  return hours * 3600 + minutes * 60 + seconds;
}

/**
 * Check if a cache entry is still valid
 * @param cachedAt - When the entry was cached
 * @param ttl - Time-to-live in milliseconds
 * @returns True if cache entry is still valid
 */
export function isCacheValid(cachedAt: number, ttl: number): boolean {
  return Date.now() - cachedAt < ttl;
}

/**
 * Detect summary mode from user query
 * @param query - User's voice query (lowercased)
 * @returns Detected summary mode
 */
export function detectSummaryMode(query: string): SummaryMode {
  const normalizedQuery = query.toLowerCase().trim();

  // Check deep mode triggers first (more specific)
  for (const trigger of SUMMARY_MODE_TRIGGERS.deep) {
    if (normalizedQuery.includes(trigger)) {
      return "deep";
    }
  }

  // Default to... default mode
  return "default";
}
